{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"proyecto_training_data.npy\").astype(np.float32)\n",
    "x = dataset[:,1].astype(np.float32)\n",
    "y = dataset[:,0].astype(np.float32)\n",
    "n = len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global graph is defined as follows:\n",
    "\n",
    "* Three place holders (X,Y,learning_rate) because those values change in training process\n",
    "* Two Variables, X and Y which are the trainable params\n",
    "* Two operation nodes multiply and addition, necessary to linear regression (Hypothesis)\n",
    "* A cost function to obtain the cost of each epoch\n",
    "* A optimizer node with gradient descent algorithm to find trainable params that minize the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\envs\\galileo_python\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\envs\\galileo_python\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    X = tf.placeholder(\"float\") \n",
    "    Y = tf.placeholder(\"float\") \n",
    "    learning_rate = tf.placeholder(\"float\")\n",
    "    W = tf.Variable(0, name = \"W\", dtype=\"float\")\n",
    "    b = tf.Variable(0, name = \"b\", dtype=\"float\")\n",
    "    y_pred = tf.add(tf.multiply(X, W), b)\n",
    "    cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)\n",
    "    cost_summary = tf.summary.scalar(\"cost\",cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training params are defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard graph visual representation\n",
    "\n",
    "<img src=\"images/grafo.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(lr):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.Session(graph=g) as sess: \n",
    "        # Initializing the Variables \n",
    "\n",
    "        writer = tf.summary.FileWriter('./graphs/lr='+str(lr), sess.graph)\n",
    "        sess.run(init) \n",
    "        # Iterating through all the epochs \n",
    "        for epoch in range(51): \n",
    "\n",
    "            # Feeding each data point into the optimizer using Feed Dictionary \n",
    "            sess.run(optimizer, feed_dict = {X : x, Y : y,learning_rate:lr}) \n",
    "\n",
    "            # Displaying the result after every 50 epochs \n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                # Calculating the cost a every epoch \n",
    "                c,co,we,inte= sess.run([cost_summary,cost,W,b],feed_dict = {X : x, Y : y,learning_rate:lr}) \n",
    "                writer.add_summary(c, epoch+1)\n",
    "                print(\"Epoch\", (epoch + 1), \": cost =\", co, \"W =\", we, \"b =\", inte) \n",
    "                \n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with  learning_rate equals to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : cost = 18123864000.0 W = 1169.12 b = 177.60818\n",
      "Epoch 20 : cost = 16835781000.0 W = 2292.2642 b = 348.03833\n",
      "Epoch 30 : cost = 15647072000.0 W = 3371.2412 b = 511.57285\n",
      "Epoch 40 : cost = 14550075000.0 W = 4407.789 b = 668.48315\n",
      "Epoch 50 : cost = 13537711000.0 W = 5403.5776 b = 819.02985\n"
     ]
    }
   ],
   "source": [
    "training(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost visualization to learning_rate equals to 0.0001\n",
    "<img src=\"images/cost_learning00001.PNG\">\n",
    "\n",
    "With this learning rate we can see the minimum cost achieved is 13537711000.0  although the cost decrement probably the steps are short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with  learning_rate equals to 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : cost = 9413964000.0 W = 9972.472 b = 1507.7444\n",
      "Epoch 20 : cost = 4953173500.0 W = 16600.504 b = 2493.3406\n",
      "Epoch 30 : cost = 2984042800.0 W = 21006.555 b = 3132.0398\n",
      "Epoch 40 : cost = 2114733300.0 W = 23936.365 b = 3540.2747\n",
      "Epoch 50 : cost = 1730888600.0 W = 25885.383 b = 3795.4011\n"
     ]
    }
   ],
   "source": [
    "training(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost visualization to learning_rate equals to 0.001\n",
    "<img src=\"images/cost_learning0001.PNG\">\n",
    "The cost is reduced significantly compared to the previous learning rate, we can reject the learning rate with value 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with  learning_rate equals to 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : cost = 1427231700.0 W = 29588.61 b = 4127.9565\n",
      "Epoch 20 : cost = 1424247000.0 W = 29839.729 b = 3677.7544\n",
      "Epoch 30 : cost = 1421931600.0 W = 29915.021 b = 3202.4307\n",
      "Epoch 40 : cost = 1419638000.0 W = 29988.914 b = 2729.207\n",
      "Epoch 50 : cost = 1417366300.0 W = 30062.447 b = 2258.2349\n"
     ]
    }
   ],
   "source": [
    "training(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost visualization to learning_rate equals to 0.01\n",
    "<img src=\"images/cost_learning001.PNG\">\n",
    "\n",
    "In this case the cost reduction is too short, it seems like the function converge in that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with  learning_rate equals to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : cost = 6.588225e+19 W = -1791751200.0 b = -279753180.0\n",
      "Epoch 20 : cost = 2.3992863e+29 W = -108128930000000.0 b = -16882305000000.0\n",
      "Epoch 30 : cost = inf W = -6.5252695e+18 b = -1.01879854e+18\n",
      "Epoch 40 : cost = inf W = -3.9378135e+23 b = -6.148158e+22\n",
      "Epoch 50 : cost = inf W = -2.3763574e+28 b = -3.710237e+27\n"
     ]
    }
   ],
   "source": [
    "training(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost visualization to learning_rate equals to 0.1\n",
    "The cost does not converge, we reject this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with  learning_rate equals to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : cost = inf W = -2.4577684e+20 b = -3.837344e+19\n",
      "Epoch 20 : cost = inf W = -2.0344807e+36 b = -3.1764599e+35\n",
      "Epoch 30 : cost = nan W = nan b = nan\n",
      "Epoch 40 : cost = nan W = nan b = nan\n",
      "Epoch 50 : cost = nan W = nan b = nan\n"
     ]
    }
   ],
   "source": [
    "training(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost visualization to learning_rate equals to 1\n",
    "\n",
    "The cost does not converge, we reject this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with  learning_rate equals to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : cost = inf W = -3.0864556e+30 b = -4.8189223e+29\n",
      "Epoch 20 : cost = nan W = nan b = nan\n",
      "Epoch 30 : cost = nan W = nan b = nan\n",
      "Epoch 40 : cost = nan W = nan b = nan\n",
      "Epoch 50 : cost = nan W = nan b = nan\n"
     ]
    }
   ],
   "source": [
    "training(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost visualization to learning_rate equals to 10\n",
    "\n",
    "The cost does not converge, we reject this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Based on the previous evidence we found that the better learning rate is 0.001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
